---
layout: post
title:  "Practical Machine Learning"
date:   2019-03-22 11:24:29 +0400
categories: DS-C8
permalink: "/ds-journey/practical-ml"
---

**Course 8/10 of the Specialization**

This is the course I have been most excited about since beginning this specialization. I am sure this is the case for most of the students as well.

The first week was a basic introduction as usual. Some of the concepts like types of errors (true positive, false negative) was already familiar to me from one of my graduate course where I presented on Hypothesis testing. But nevertheless, the lectures on this concept was well explained.

The next section of the course introduced the caret package in R. This was great for preprocessing, training and test set and all those good stuff. I really liked the fact that they used the SPAM email case as an example here. It's also worth noting that they introduced how we can use the regression technique as a predictor (so basically the previous course seen as ML tool)

Week 3 and 4 were relatively short. They introduced Random Forest (which was amazing) and Boosting in week 3. The decision tree was well explained with the Obama-Clinton example. There was this one lecture on a model-based prediction but it was theoretical for the most part. In week 4, forecasting and unsupervised prediction was introduced but these lectures were very short and just introduced the concept. This was followed by a course project, which I did not enjoy that much, partly because the dataset was similar to one of the previous courses. It was the one on wearables used to collect data and predicting what exercises people performed and how frequently each activity was performed. 

Overall, the lectures were good but the project could have been better (to allow us to implement multiple ML techniques that we learned).
My Rating: 8.1/10

![Course 8 certificate](/images/8.png)